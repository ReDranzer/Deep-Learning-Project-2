# -*- coding: utf-8 -*-
"""Untitled

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m8hw_IGv9EqORRnzPmEFvX3Ra069mPEm
"""

from google.colab import drive
drive.mount('/content/gdrive')
import torch
import torchvision
data1 = torchvision.datasets.FashionMNIST(' ./content/gdrive', train=True, transform=torchvision.transforms.ToTensor(), target_transform=None, download=True)
trainX,trainY = torch.load(" ./content/gdrive/FashionMNIST/processed/training.pt")
testX,testY = torch.load(" ./content/gdrive/FashionMNIST/processed/test.pt")
data21 = torchvision.datasets.FashionMNIST(' ./content/gdrive', train=False, transform=torchvision.transforms.ToTensor(), target_transform=None, download=True)
from torch.autograd import Variable
path = '/content/gdrive/My Drive/DL2_model/model_cnn.pth'
from sklearn import metrics

losses = [];
import torch.nn as nn
import numpy as np
from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout
train2 = torch.utils.data.DataLoader(data1, batch_size=16, shuffle=True)
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.layer1 = nn.Sequential(
            nn.Conv2d(1, 16, kernel_size=5, padding=2),
            nn.BatchNorm2d(16),
            nn.ReLU(),
            nn.MaxPool2d(2))
        self.layer2 = nn.Sequential(
            nn.Conv2d(16, 32, kernel_size=5, padding=2),
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(2))
        self.fc = nn.Linear(7*7*32, 10)
        
    def forward(self, x):
        out = self.layer1(x)
        out = self.layer2(out)
        out = out.view(out.size(0), -1)
        out = self.fc(out)
        return out
cnn = CNN();
criterion = nn.CrossEntropyLoss();
optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001);    
num_epochs=40
batch_size=16
pre=np.Inf
for epoch in range(num_epochs):
    for i ,(images, labels) in enumerate(train2):
        images = Variable(images.float())
        labels = Variable(labels)
        optimizer.zero_grad()
        outputs = cnn(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
    losses.append(loss.item());    
    print ('Epoch:', epoch, 'Loss:', loss)
    if(loss<pre):
      torch.save(cnn.state_dict(),path)
      pre=loss
      print("CNN Model Saved!")



cnn= CNN()
cnn.load_state_dict(torch.load(path))
cnn.eval()
correct = 0
total = 0
loss_fn = torch.nn.CrossEntropyLoss()
#data2=Variable(torch.Tensor.float((data2)))
data2 = torch.utils.data.DataLoader(data21, batch_size=len(testY), shuffle=False)
for (images, labels) in (data2):
    images = Variable(images.float())
    outputs = cnn(images)
    _, predicted = torch.max(outputs.data, 1)
    Prediction=list(outputs.max(1)[1].data.tolist())
    loss = loss_fn(outputs, testY)
    conf_matrix = metrics.confusion_matrix(Prediction, testY)
    print(conf_matrix)
    print(loss)
    total += labels.size(0)
    correct += (predicted == labels).sum()